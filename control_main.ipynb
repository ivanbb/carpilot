{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main control script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from GetKeys import get_key\n",
    "from Screen import get_screen\n",
    "import Detect_car\n",
    "from vjoy import vJoy\n",
    "\n",
    "X1 = 300\n",
    "Y1 = 340\n",
    "WEIGHT = 400 + X1\n",
    "HEIGHT = 350 + Y1\n",
    "\n",
    "size = (X1, Y1, WEIGHT, HEIGHT)\n",
    "\n",
    "roi = [300,428,400+300,300+428]\n",
    "gear_roi = [300+537+5,425+90+5,308+537+5,425+98+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanShift(img):\n",
    "    res = cv2.pyrMeanShiftFiltering(img, 1, 50)\n",
    "    return res\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('km.pickle', 'rb') as f:\n",
    "    \"\"\"Loading pretrained k-means\"\"\"\n",
    "    km = pickle.load(f)\n",
    "\n",
    "def use_km(img, orig_img):\n",
    "        #get indeces of non-ziro color\n",
    "        indices = np.argwhere(img>1)\n",
    "        \"\"\"\n",
    "        Cluster prediction\n",
    "        Clusters 2 and 3 are marking lines, others are noise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \"\"\"\n",
    "            Gets the pixels belonging to the line clusters\n",
    "            \"\"\"\n",
    "            lines = km.predict(indices)\n",
    "            left_indx = np.argwhere(lines==1)\n",
    "            right_indx = np.argwhere((lines==0) | (lines==2))\n",
    "            \"\"\"\n",
    "            Get pixel coordinates of lines\n",
    "            \"\"\"\n",
    "            left = np.take(indices, left_indx, axis=0).reshape(left_indx.shape[0], 2)\n",
    "            right = np.take(indices, right_indx, axis=0).reshape(right_indx.shape[0], 2)\n",
    "            \"\"\"\n",
    "            and fill them with color\n",
    "            other pixels are set to zero\n",
    "            \"\"\"\n",
    "            orig_img[:, :] = 0\n",
    "            orig_img[right[:,0], right[:,1]] = 255\n",
    "            orig_img[left[:,0], left[:,1]] = 255\n",
    "            \n",
    "        except:\n",
    "            orig_img[:, :] =0\n",
    "            \n",
    "        return orig_img\n",
    "\n",
    "def calc_dif(img, delta=1):\n",
    "    gray = np.apply_along_axis(lambda x: np.average(x), 1, img)\n",
    "    objects = []\n",
    "    for idx, (x0, x1) in enumerate(zip(gray[:-1], gray[1:])):\n",
    "        if (x1-x0)>delta:\n",
    "            objects.append(idx)\n",
    "    return objects\n",
    "\n",
    "def img_proceed(roi):\n",
    "    '''\n",
    "    processing image: \n",
    "    resize->mean shift->gray->blur->trashhold->dilate->k-means\n",
    "    The image is taken from Get_screen process\n",
    "    '''\n",
    "    orig_img = get_screen(roi)\n",
    "        \n",
    "    orig_img = cv2.resize(orig_img, (256,256))\n",
    "    \n",
    "    orig_img = MeanShift(orig_img)\n",
    "        \n",
    "    gray = cv2.cvtColor(orig_img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    processed_img = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    processed_img = cv2.adaptiveThreshold(processed_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, -22)\n",
    "    processed_img = cv2.dilate(processed_img, None, iterations = 1)\n",
    "        \n",
    "    #removing noise by using k-means\n",
    "    processed_img = use_km(processed_img, processed_img)\n",
    "        \n",
    "    return processed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brith_img(orig_img):\n",
    "    image, cars, dist = Detect_car.main(orig_img)\n",
    "    return image, cars, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vj = vJoy()\n",
    "OUTPUT_NORMALIZATION = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(predict, coef):\n",
    "    \"\"\"\n",
    "    Set normalised wheel's angle,\n",
    "    corrected by speed's coefficient\n",
    "    \"\"\"\n",
    "    angle = predict\n",
    "    angle *= OUTPUT_NORMALIZATION*(coef/100)\n",
    "    try:\n",
    "        return int(angle)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x - gear number\n",
    "y - wheel's coefficient \n",
    "\n",
    "\"\"\"\n",
    "x = [7,8,9,10]\n",
    "y = [200, 150, 145, 140]\n",
    "z = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "def set_coef(gear):\n",
    "    return int(p(gear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tree.pickle', 'rb') as f:\n",
    "    \"\"\"Loading pretrained pandom forest model for angle prediction\"\"\"\n",
    "    tree = pickle.load(f)\n",
    "    \n",
    "with open('geartree.pickle', 'rb') as f:\n",
    "    \"\"\"Loading pretrained decision tree model for gear number recognition\"\"\"\n",
    "    treec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main cycle, in which the image preprocessing function is called, the included gear is recognized, and the model is predicted for the steering angle, the cars are recognized on the lane and the distance to them is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    vj.open()\n",
    "    \"\"\"\n",
    "    Gets the coefficient for steering\n",
    "    \"\"\"\n",
    "    gear = get_screen(gear_roi)   \n",
    "    gear = cv2.cvtColor(gear, cv2.COLOR_RGB2GRAY)\n",
    "    coef = set_coef(treec.predict([gear.ravel()]))\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets visualization of the hitmap \n",
    "    and detected vehicles \n",
    "    and the distance to them.\n",
    "    \"\"\"\n",
    "    cars_image = cv2.resize(get_screen(size), (200, 175))\n",
    "    brith, cars, dist = brith_img(cars_image)\n",
    "    \n",
    "    \"\"\"\n",
    "    Image processing and angle prediction\n",
    "    \"\"\"\n",
    "    result_img = img_proceed(roi)\n",
    "    \n",
    "    res = cv2.resize(result_img, (128,128))\n",
    "    res = res.reshape(1, 128*128)\n",
    "\n",
    "    pred = tree.predict(res)\n",
    "\n",
    "    angle = get_angle(pred[0], coef)\n",
    "\n",
    "    \"\"\"\n",
    "    Calculation of acceleration / deceleration \n",
    "    based on the distance to the found cars\n",
    "    \"\"\"\n",
    "    accel = 30000\n",
    "    if dist>1:\n",
    "        pct = 0.09\n",
    "        accel = int(-200*(dist-1)/pct+20000)\n",
    "\n",
    "    joystickPosition = vj.generateJoystickPosition(wAxisX = OUTPUT_NORMALIZATION+angle, wAxisY = accel)\n",
    "    vj.update(joystickPosition)\n",
    "    \n",
    "    cv2.imshow('Road', result_img)\n",
    "    cv2.imshow('Gear', gear)\n",
    "    cv2.imshow('Brithness', brith)\n",
    "    cv2.imshow('Cars', cars)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
